{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ed4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import jieba as jb\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e497f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /Users/lilyhe/opt/anaconda3/lib/python3.8/site-packages (0.42.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020a486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#中文分局\n",
    "def SentsTokenizer4Ch(text):\n",
    "    #sentences = re.split('(。|！|\\!|\\.|？|\\?)',text)\n",
    "    sentences = re.split('(。|！|\\!|？|\\?)',text)\n",
    "    new_sents = []\n",
    "    for i in range(int(len(sentences)/2)):\n",
    "        sent = sentences[2*i] + sentences[2*i+1]\n",
    "        sent = sent.replace('\\r\\n','')\n",
    "        sent = sent.strip()\n",
    "        new_sents.append(sent)\n",
    "    return new_sents\n",
    "\n",
    "#删除所有符号,只保留字母、数字和中文\n",
    "def remove_punctuation(line):\n",
    "    #line = str(line)\n",
    "    if line.strip()=='':\n",
    "        return ''\n",
    "    rule = re.compile(u\"[^a-zA-Z0-9\\u4E00-\\u9FA5]\")\n",
    "    line = rule.sub('',line)\n",
    "    return line\n",
    " \n",
    "#中文停用词\n",
    "def stopwordslist(filepath):  \n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf8',errors='ignore').readlines()]  \n",
    "    return stopwords  \n",
    "\n",
    "\n",
    "#加载停用词\n",
    "stopwords = stopwordslist(\"/Users/lilyhe/Documents/NLP_BERT/Chatbot_chinese/data/chineseStopWords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da80c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7月3日0—24时，31个省（自治区、直辖市）和新疆生产建设兵团报告新增确诊病例72例。',\n",
       " '其中境外输入病例31例（广东9例，上海7例，福建5例，内蒙古2例，浙江2例，北京1例，天津1例，辽宁1例，江西1例，河南1例，四川1例），含7例由无症状感染者转为确诊病例（广东4例，天津1例，福建1例，河南1例）；本土病例41例（安徽29例，江苏4例，山东4例，上海2例，福建1例，广东1例），含2例由无症状感染者转为确诊病例（安徽1例，山东1例）。',\n",
       " '无新增死亡病例。',\n",
       " '无新增疑似病例。',\n",
       " '当日新增治愈出院病例50例，其中境外输入病例32例，本土病例18例（内蒙古7例，上海6例，北京5例），解除医学观察的密切接触者3759人，重症病例与前一日持平。',\n",
       " '境外输入现有确诊病例299例（无重症病例），无现有疑似病例。',\n",
       " '累计确诊病例19485例，累计治愈出院病例19186例，无死亡病例。',\n",
       " '截至7月3日24时，据31个省（自治区、直辖市）和新疆生产建设兵团报告，现有确诊病例532例（无重症病例），累计治愈出院病例220165例，累计死亡病例5226例，累计报告确诊病例225923例，无现有疑似病例。',\n",
       " '累计追踪到密切接触者4282315人，尚在医学观察的密切接触者61500人。']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile = \"/Users/lilyhe/Documents/NLP_BERT/Chatbot_chinese/data/Covid19.txt\"\n",
    "\n",
    "text = codecs.open(myfile,encoding=\"utf16\").read()\n",
    "#with open(myfile, 'rb') as f: text = f.read()\n",
    "\n",
    "sent_tokens = SentsTokenizer4Ch(text)\n",
    "sent_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6940aa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/lb/f39r117d24l1d72_dd9psjcc0000gn/T/jieba.cache\n",
      "Loading model cost 0.637 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>clean_set</th>\n",
       "      <th>cut_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7月3日0—24时，31个省（自治区、直辖市）和新疆生产建设兵团报告新增确诊病例72例。</td>\n",
       "      <td>7月3日024时31个省自治区直辖市和新疆生产建设兵团报告新增确诊病例72例</td>\n",
       "      <td>7 月 3 日 024 时 31 个省 自治区 直辖市 和 新疆生产建设兵团 报告 新增 确...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>其中境外输入病例31例（广东9例，上海7例，福建5例，内蒙古2例，浙江2例，北京1例，天津1...</td>\n",
       "      <td>其中境外输入病例31例广东9例上海7例福建5例内蒙古2例浙江2例北京1例天津1例辽宁1例江西...</td>\n",
       "      <td>其中 境外 输入 病例 31 例 广东 9 例 上海 7 例 福建 5 例 内蒙古 2 例 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>无新增死亡病例。</td>\n",
       "      <td>无新增死亡病例</td>\n",
       "      <td>无 新增 死亡 病例</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>无新增疑似病例。</td>\n",
       "      <td>无新增疑似病例</td>\n",
       "      <td>无 新增 疑似病例</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>当日新增治愈出院病例50例，其中境外输入病例32例，本土病例18例（内蒙古7例，上海6例，北...</td>\n",
       "      <td>当日新增治愈出院病例50例其中境外输入病例32例本土病例18例内蒙古7例上海6例北京5例解除...</td>\n",
       "      <td>当日 新增 治愈 出院 病例 50 例 其中 境外 输入 病例 32 例 本土 病例 18 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent  \\\n",
       "0       7月3日0—24时，31个省（自治区、直辖市）和新疆生产建设兵团报告新增确诊病例72例。   \n",
       "1  其中境外输入病例31例（广东9例，上海7例，福建5例，内蒙古2例，浙江2例，北京1例，天津1...   \n",
       "2                                           无新增死亡病例。   \n",
       "3                                           无新增疑似病例。   \n",
       "4  当日新增治愈出院病例50例，其中境外输入病例32例，本土病例18例（内蒙古7例，上海6例，北...   \n",
       "\n",
       "                                           clean_set  \\\n",
       "0             7月3日024时31个省自治区直辖市和新疆生产建设兵团报告新增确诊病例72例   \n",
       "1  其中境外输入病例31例广东9例上海7例福建5例内蒙古2例浙江2例北京1例天津1例辽宁1例江西...   \n",
       "2                                            无新增死亡病例   \n",
       "3                                            无新增疑似病例   \n",
       "4  当日新增治愈出院病例50例其中境外输入病例32例本土病例18例内蒙古7例上海6例北京5例解除...   \n",
       "\n",
       "                                            cut_sent  \n",
       "0  7 月 3 日 024 时 31 个省 自治区 直辖市 和 新疆生产建设兵团 报告 新增 确...  \n",
       "1  其中 境外 输入 病例 31 例 广东 9 例 上海 7 例 福建 5 例 内蒙古 2 例 ...  \n",
       "2                                         无 新增 死亡 病例  \n",
       "3                                          无 新增 疑似病例  \n",
       "4  当日 新增 治愈 出院 病例 50 例 其中 境外 输入 病例 32 例 本土 病例 18 ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#删除除字母,数字，汉字以外的所有符号\n",
    "df = pd.DataFrame(sent_tokens, columns=['sent'])\n",
    "df['clean_set']=  df['sent'].apply(remove_punctuation)\n",
    "\n",
    "#分词，并过滤停用词\n",
    "# df['cut_sent'] = df['clean_set'].apply(lambda x: \" \".join([w for w in list(jb.cut(x)) if w not in stopwords]))\n",
    "df['cut_sent'] = df['clean_set'].apply(lambda x: \" \".join([w for w in list(jb.cut(x))]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1a771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"你好\", \"hi\", \"有人\", \"在吗\", \"嗨\",\"在不在\",\"有人吗\",'在','有人')\n",
    "GREETING_RESPONSES = [\"你好\",  \"我在\", \"请问,有什么可以帮您的吗?\", \"你好，我在\", \"你好，很高兴见到你！\"]\n",
    "\n",
    "def greeting(sentence):\n",
    "    rule = re.compile(u\"[^a-zA-Z0-9\\u4E00-\\u9FA5]\")\n",
    "    text = rule.sub('',sentence)\n",
    "    if text in GREETING_INPUTS:\n",
    "        return random.choice(GREETING_RESPONSES)\n",
    "    \n",
    "    wordlist =  [w for w in jb.cut(sentence)]\n",
    "    for word in wordlist:\n",
    "        if word in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e562d2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，我在'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeting('有人在吗？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83580b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    user_response  = remove_punctuation(user_response)\n",
    "    user_response= \" \".join([w for w in list(jb.cut(user_response)) if w not in stopwords])\n",
    "    cut_sent = df.cut_sent.values.tolist()\n",
    "    cut_sent.append(user_response)\n",
    "    tfidf = TfidfVectorizer()\n",
    "\n",
    "    tfidf_vec = tfidf.fit_transform(cut_sent)\n",
    "\n",
    "    cos_sim = cosine_similarity(tfidf_vec[-1], tfidf_vec)\n",
    "    idx=cos_sim.argsort()[0][-2]\n",
    "    flat = cos_sim.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"对不起,我不理解您的意思,我还是个小白...!\"\n",
    "        return(robo_response)\n",
    "    else:\n",
    "        robo_response = robo_response+df.sent.values[idx]\n",
    "        return(robo_response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1812be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "机器人: 我的名字叫小白. 我可以回答您关于Covid最新政策的问题. 如果您想退出, 请输入:bye !\n",
      "现在什么政策？\n",
      "机器人: 对不起,我不理解您的意思,我还是个小白...!\n",
      "\n",
      "境外输入病例有多少？\n",
      "机器人: 境外输入现有确诊病例299例（无重症病例），无现有疑似病例。\n",
      "\n",
      "新增死亡病例有多少？\n",
      "机器人: 无新增死亡病例。\n",
      "\n",
      "新增多少？\n",
      "机器人: 无新增疑似病例。\n",
      "\n",
      "新增确诊有多少？\n",
      "机器人: 无新增疑似病例。\n",
      "\n",
      "上海怎么样？\n",
      "机器人: 其中境外输入病例31例（广东9例，上海7例，福建5例，内蒙古2例，浙江2例，北京1例，天津1例，辽宁1例，江西1例，河南1例，四川1例），含7例由无症状感染者转为确诊病例（广东4例，天津1例，福建1例，河南1例）；本土病例41例（安徽29例，江苏4例，山东4例，上海2例，福建1例，广东1例），含2例由无症状感染者转为确诊病例（安徽1例，山东1例）。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"机器人: 我的名字叫小白. 我可以回答您关于Covid最新政策的问题. 如果您想退出, 请输入:bye !\")\n",
    "\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='多谢' or user_response=='谢谢' ):\n",
    "            flag=False\n",
    "            print(\"机器人: 不用谢！\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"机器人: \"+greeting(user_response))\n",
    "                print()\n",
    "            else:\n",
    "                print(\"机器人: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                print()\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"小白: 再见! 欢迎再次光临!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026de66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20b20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and NLP\n",
    "\n",
    "Name: Liping He\n",
    "\n",
    "abc123: llt949\n",
    "\n",
    "Blank notebook to be used for class exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lilyhe/Documents/UTSA fall 2021/IS6713/week9/PS3-Zip-File/Week-9-Lab-Copy1\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "/Users/lilyhe/Documents/UTSA fall 2021/MKT697/exercise_files/retail 1.gdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Write code to load the data in the \"iris.csv\" into numpy arrays.\n",
    "\n",
    "The frst 4 columns are the features/attributes. The last column is the\n",
    "class. Simply load the class as a list of strings. Don't forget to convert the\n",
    "dataset into a numpy array. You can use either DictVectorizer or the CSV\n",
    "method on the previous slide to load the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'iris.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3d09abb5c441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iris.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0min_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0min_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iris.csv'"
     ]
    }
   ],
   "source": [
    "with open('iris.csv') as in_file:\n",
    "    count = 0\n",
    "    for row in in_file:\n",
    "        print(row.strip())\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# Write code here\n",
    "vec = DictVectorizer(sparse = False)\n",
    "X_dicts = []\n",
    "y =[]\n",
    "with open ('iris.csv') as in_file:\n",
    "    iCSV = csv.reader(in_file, delimiter =',')\n",
    "    for row in iCSV:\n",
    "        tmp = {\"f0\":float(row[0]),\n",
    "               \"f1\":float(row[1]),\n",
    "               \"f2\":float(row[2]),\n",
    "               \"f3\":float(row[3])}\n",
    "        X_dicts.append(tmp)\n",
    "        y.append(row[-1])\n",
    "X = vec.fit_transform(X_dicts)\n",
    "y= np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Using the iris data you loaded in Exercise 1, do the following:\n",
    "\n",
    "- Use train_test_split() to divide the iris dataset. (use 0.2 for the\n",
    "test size). Set random_state to 42.\n",
    "- Train an SVM on the train split and evaluate using accuracy on the\n",
    "test split.\n",
    "- Fiddle with the parameters of the SVM to see how it effects the\n",
    "performance.\n",
    "- Calculate the accuracy on the train split. Is there a difference between the train/test accuracies?\n",
    "\n",
    "Next, try using a different classifier, a random forest, and see how it\n",
    "compares to the SVM\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "Note that this is a toy dataset, so all scores will be high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Write code here\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.2)\n",
    "clf = SVC(C=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_val)\n",
    "print(accuracy_score(y_val, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Using the train/test iris dataset split from exercise 2. Train a model on the training dataset using GridSearchCV with the SVC kernel parameters \"rbf\" and \"linear\",and C parameters 0.001, 0.01, 0.1, 1., and 10. Print the training and\n",
    "validation scores for the best set of parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n"
     ]
    }
   ],
   "source": [
    "# Write code here\n",
    "svc = SVC()\n",
    "params ={'kernel':['rbf','linear'], 'C':[0.001,0.01,0.1,1.,10.]}\n",
    "clf =GridSearchCV(svc, params, cv =3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "The tab (\\t) separated file \"sentiment-twitter-data.tsv\" contains tweets annotated for sentiment. Load the data then do the following:\n",
    "\n",
    "- split the dataset into a train/test split.\n",
    "- create a bag of words feature representation for the tweets using the CountVectorizer\n",
    "- Use grid-search (CV) on the train split to find the best C parameters for a LinearSVC classifier. Only test 2 C values to reduce overhead (0.1 and 1.). Also, use a 2-fold CV, i.e., cv=2.\n",
    "- report (print) the accuracy, micro F1, and macro F1 of the final classifier on the test data and train data\n",
    "- How many features were created with the bag of words representation?\n",
    "\n",
    "file path: ./sentiment-twitter-data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264183816548130816\t15140428\tpositive\tGas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\n",
      "264249301910310912\t18516728\tnegative\tIranian general says Israel's Iron Dome can't deal with their missiles (keep talking like that and we may end up finding out)\n",
      "264105751826538497\t147088367\tpositive\twith J Davlar 11th. Main rivals are team Poland. Hopefully we an make it a successful end to a tough week of training tomorrow.\n",
      "264094586689953794\t332474633\tnegative\tTalking about ACT's &amp;&amp; SAT's, deciding where I want to go to college, applying to colleges and everything about college stresses me out.\n",
      "254941790757601280\t557103111\tnegative\tThey may have a SuperBowl in Dallas, but Dallas ain't winning a SuperBowl. Not with that quarterback and owner. @S4NYC @RasmussenPoll\n",
      "264169034155696130\t382403760\tneutral\tIm bringing the monster load of candy tomorrow, I just hope it doesn't get all squiched\n",
      "263192091700654080\t344222239\tobjective-OR-neutral\tApple software, retail chiefs out in overhaul: SAN FRANCISCO Apple Inc CEO Tim Cook on Monday replaced the heads... http://t.co/X49ZEOsG\n",
      "263398998675693568\t812957996\tpositive\t@oluoch @victor_otti @kunjand I just watched it! Sridevi's comeback.... U remember her from the 90s?? Sun mornings on NTA ;)\n",
      "260200142420992000\t332530284\tobjective\t#Livewire Nadal confirmed for Mexican Open in February: Rafael Nadal is set to play at the Me... http://t.co/zgUXpcnC #LiveWireAthletics\n",
      "264087629237202944\t61903760\tpositive\t@MsSheLahY I didnt want to just pop up... but yep we have chapel hill next wednesday you should come.. and shes great ill tell her you asked\n"
     ]
    }
   ],
   "source": [
    "# This is a tab seperated file, so with csv reader use delimiter=\"\\t\"\n",
    "with open('./sentiment-twitter-data.tsv') as in_file:\n",
    "    count = 0\n",
    "    for row in in_file:\n",
    "        print(row.strip())\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code here\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X_txt = []\n",
    "y = []\n",
    "with open('./sentiment-twitter-data.tsv') as in_file:\n",
    "    iCSV = csv.reader(in_file, delimiter = '\\t')\n",
    "    for row in iCSV:\n",
    "        X_txt.append(row[-1])\n",
    "        y.append(row[2])\n",
    "X_txt = np.array(X_txt)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into a train/test split\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "X_txt_train, X_txt_text, y_train, y_test=train_test_split(X_txt,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a bag of words feature representation for the tweets using the CountVectorizer\n",
    "vec = CountVectorizer(ngram_range=(1,1), min_df=3)\n",
    "X_train = vec.fit_transform(X_txt_train)\n",
    "X_test = vec.transform(X_txt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyhe/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=LinearSVC(), param_grid={'C': [0.1, 1.0]})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use grid-search (CV) on the train split to find the best C parameters for a LinearSVC classifier.\n",
    "svc = LinearSVC()\n",
    "params = {\"C\":[0.1,1.]}\n",
    "clf =GridSearchCV(svc, params,cv=2)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43118229654795376"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = clf.predict(X_test)\n",
    "preds2 = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45971267957526546\n",
      "0.9006405249179815\n",
      "0.45971267957526546\n",
      "0.9006405249179816\n",
      "0.38546785646995696\n",
      "0.8946139661290985\n"
     ]
    }
   ],
   "source": [
    "#report (print) the accuracy, micro F1, and macro F1 of the final classifier on the test data and train data\n",
    "#accuracy_score\n",
    "print(accuracy_score(y_test, preds1))\n",
    "print(accuracy_score(y_train, preds2))\n",
    "\n",
    "#micro F1\n",
    "\n",
    "print(f1_score(y_test, preds1, average='micro'))\n",
    "print(f1_score(y_train, preds2, average='micro'))\n",
    "\n",
    "#macro F1\n",
    "print(f1_score(y_test, preds1, average='macro'))\n",
    "print(f1_score(y_train, preds2, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6401, 4297) (1601, 4297)\n"
     ]
    }
   ],
   "source": [
    "#How many features were created with the bag of words representation?\n",
    "print(X_train.shape, X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

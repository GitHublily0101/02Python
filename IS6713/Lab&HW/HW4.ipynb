{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae3fe885-1430-41e1-bfe2-7af7db6082dc",
   "metadata": {},
   "source": [
    "# Machine Learning Challenge\n",
    "The Rowdy Coderunners: Lily He, Richard Tarbell, Jenna Wallace\n",
    "\n",
    "### Step 1: Import the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72fcf3e6-0bfa-4ad3-81b9-180117acdb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_txt_train = []\n",
    "y_txt_train = []\n",
    "\n",
    "with open('./train.tsv', encoding=\"utf8\") as myTrainFile:\n",
    "    train = csv.reader(myTrainFile, delimiter='\\t', quoting = csv.QUOTE_NONE)\n",
    "    for i in train:\n",
    "        X_txt_train.append(i[1])\n",
    "        y_txt_train.append(i[2])\n",
    "\n",
    "\n",
    "        \n",
    "X_txt_test = []\n",
    "y_txt_test = []\n",
    "ID_txt_test = []\n",
    "\n",
    "with open('./test.tsv', encoding=\"utf8\") as myTestFile:\n",
    "    test = csv.reader(myTestFile, delimiter='\\t', quoting = csv.QUOTE_NONE)\n",
    "    for i in test:\n",
    "        ID_txt_test.append(i[0])\n",
    "        X_txt_test.append(i[1])\n",
    "        y_txt_test.append(i[2])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f055e2a-a43e-4c53-ba53-08df9786867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER She should ask a few native Americans what their take on this is.\n",
      "UNT\n",
      "10592 10592\n"
     ]
    }
   ],
   "source": [
    "# make sure the data is read correctly\n",
    "print(X_txt_train[0])\n",
    "print(y_txt_train[0])\n",
    "print(len(X_txt_train), len(y_txt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553ecd18-b0c7-443b-9543-8e1a40e33c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER Nancy Lee Grahn You Are Awesome! I have been a fan since Santa Barbara!! Alex Davis also Rocks!!!!! Thank you !!!\n",
      "NOT\n",
      "2648 2648\n"
     ]
    }
   ],
   "source": [
    "print(X_txt_test[0])\n",
    "print(y_txt_test[0])\n",
    "print(len(X_txt_test), len(y_txt_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c003a4c-3b15-432a-befc-fce932d7ab4d",
   "metadata": {},
   "source": [
    "### Step 2: Convert the lists to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "388efb87-8a80-410d-97d2-924c12979f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_txt_train = np.array(X_txt_train)\n",
    "y_txt_train = np.array(y_txt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9fb081c-3b3f-46e9-bb43-180151d5b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_txt_test = np.array(X_txt_test)\n",
    "y_txt_test = np.array(y_txt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aaec92-b50b-407b-b784-ab0933cf7c82",
   "metadata": {},
   "source": [
    "### Step 3: Explore best vectorizing parameters\n",
    "Run a pipeline to determine best parameters for vectorizing (n-grams, df, whether to include stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21245a47-7d33-4215-a85d-f0d05cc3d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.4854342905510299\n",
      "Best params: {'clf__C': 1, 'skb__k': 'all', 'vec__min_df': 1, 'vec__ngram_range': (1, 2), 'vec__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore') #turning off convergence warnings\n",
    "    \n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "pipeline = Pipeline([('vec', CountVectorizer()), \n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('clf', LinearSVC(random_state=1))])\n",
    "params = {'vec__ngram_range':[(1,1),(1,2)],\n",
    "          'vec__min_df':(1,2,4,5),\n",
    "          'vec__stop_words':['english', 'None'],\n",
    "          'skb__k':[10,500, 1000, 5000,'all'],\n",
    "         'clf__C':[0.01, 0.1,1, 10, 100, 1000]}\n",
    "\n",
    "initX_train, initX_test, inity_train, inity_test = train_test_split(X_txt_train, y_txt_train, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = GridSearchCV(pipeline, params, cv=5, scoring=\"f1_macro\")\n",
    "\n",
    "clf.fit(initX_train, inity_train)\n",
    "\n",
    "preds = clf.predict(initX_test)\n",
    "\n",
    "print('Best score:', clf.best_score_)\n",
    "print('Best params:', clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4286f-634e-4c62-95ec-9d423286f927",
   "metadata": {},
   "source": [
    "### Step 4: Feature Engineering - Target Words\n",
    "\n",
    "Define 4 new functions to count pronouns that might indicate targetted offense (you, male, female, group/nonbinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b90f2339-9c30-4960-b60c-cf24b7c49435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def youwords(sentence):\n",
    "    you_words = 0\n",
    "    for word in sentence.lower().split():\n",
    "        if re.search(\"you\", word):\n",
    "            you_words += 1\n",
    "    return you_words\n",
    "\n",
    "def malepro(sentence):\n",
    "    male = 0\n",
    "    for word in sentence.lower().split():\n",
    "        if re.search(r\"\\b(he|his|him)\\b\", word):\n",
    "            male += 1\n",
    "    return male\n",
    "\n",
    "def femalepro(sentence):\n",
    "    female = 0\n",
    "    for word in sentence.lower().split():\n",
    "        if re.search(r\"\\b(she|her|hers)\\b\", word):\n",
    "            female += 1\n",
    "    return female\n",
    "\n",
    "def nonbin(sentence):\n",
    "    nonbin = 0\n",
    "    for word in sentence.lower().split():\n",
    "        if re.search(r\"\\b(they|them|their)\\b\", word):\n",
    "            nonbin += 1\n",
    "    return nonbin\n",
    "\n",
    "def pointsCount(sentence):\n",
    "    points = 0\n",
    "    for word in sentence.lower().split():\n",
    "        if re.search(r\"!+\", word):\n",
    "            points += 1\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4683eab6-47b6-40c8-bcf2-4c669e899bda",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83fa2f86-29b6-4490-92ed-02c32ed41baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates four features, one for each group of targets\n",
    "X_train_all_targets = [] \n",
    "\n",
    "for item in X_txt_train:\n",
    "    you_counts = youwords(item)\n",
    "    male_counts = malepro(item)\n",
    "    female_counts = femalepro(item)\n",
    "    nonbin_counts = nonbin(item)\n",
    "    X_train_all_targets.append([you_counts, male_counts, female_counts, nonbin_counts])\n",
    "\n",
    "X_train_all_targets = np.array(X_train_all_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510044b8-5700-4bdd-b312-6735fd7ff4b0",
   "metadata": {},
   "source": [
    "#### For the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a96a2f01-3d21-4257-8eaa-dff0552cf503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates four features, one for each group of targets\n",
    "X_test_all_targets = [] \n",
    "\n",
    "for item in X_txt_test:\n",
    "    you_counts = youwords(item)\n",
    "    male_counts = malepro(item)\n",
    "    female_counts = femalepro(item)\n",
    "    nonbin_counts = nonbin(item)\n",
    "    X_test_all_targets.append([you_counts, male_counts, female_counts, nonbin_counts])\n",
    "\n",
    "X_test_all_targets = np.array(X_test_all_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e03442a-6cf7-4447-8d58-3f02f770d3fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 5: Feature Engineering - Positive and Negative Words\n",
    "\n",
    "Count positive and negative words in each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d20f45b7-feb4-4cd4-8209-3cdd21c7f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexiconClassifier():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Initalize the Lexicon classifer by loading lexicons. \n",
    "        \n",
    "        self.positive_words = set()\n",
    "        with open('positive-words.txt', encoding = 'utf-8') as iFile:\n",
    "            for row in iFile:\n",
    "                self.positive_words.add(row.strip())\n",
    "\n",
    "        self.negative_words = set()\n",
    "        with open('negative-words.txt', encoding='iso-8859-1') as iFile:\n",
    "            for row in iFile:\n",
    "                self.negative_words.add(row.strip())\n",
    "\n",
    "   \n",
    "    def count_pos_words(self, sentence):\n",
    "        #Returns the number of positive words in string\n",
    "            \n",
    "        num_pos_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.positive_words:\n",
    "                num_pos_words += 1\n",
    "        return num_pos_words\n",
    "\n",
    "    def count_neg_words(self, sentence):\n",
    "        #Returns the number of negative words in string\n",
    "            \n",
    "        num_neg_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.negative_words:\n",
    "                num_neg_words += 1\n",
    "        return num_neg_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f765b20-454f-4297-ae11-a38a2a760841",
   "metadata": {},
   "source": [
    "#### Training data\n",
    "Instantiate the LC classifier, loop over X_txt_train, append to new list and cast to array to create a new feature: X_train_pos_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b61fb6-de18-4903-9059-646d2201f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a feature of both positive and negative words\n",
    "myLC = LexiconClassifier()\n",
    "X_train_pos_neg = [] \n",
    "\n",
    "for item in X_txt_train:\n",
    "    pos_train_counts = myLC.count_pos_words(item)\n",
    "    neg_train_counts = myLC.count_neg_words(item)\n",
    "    X_train_pos_neg.append([pos_train_counts,neg_train_counts])\n",
    "\n",
    "X_train_pos_neg = np.array(X_train_pos_neg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76238f86-765d-4206-9079-b118397c13d4",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5503ed61-660d-494b-bb06-0e72a9a9fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a feature of both positive and negative words for the test data\n",
    "myLC = LexiconClassifier()\n",
    "X_test_pos_neg = [] \n",
    "\n",
    "for item in X_txt_test:\n",
    "    pos_test_counts = myLC.count_pos_words(item)\n",
    "    neg_test_counts = myLC.count_neg_words(item)\n",
    "    X_test_pos_neg.append([pos_test_counts,neg_test_counts])\n",
    "\n",
    "X_test_pos_neg = np.array(X_test_pos_neg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d52af-9af0-4d7a-bc70-3c5e39558b4d",
   "metadata": {},
   "source": [
    "### Step 6: Feature Engineering - Offensive Words\n",
    "\n",
    "Establish a lexicon classifier class using the bad-words.txt to determine if there are offensive words present in each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f08bff7-7192-4d59-aa4f-acf713b1d5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OffensiveClassifier():\n",
    "    def __init__(self):\n",
    "        # Initalize the Lexicon classifer by loading the bad word lexicon \n",
    "        \n",
    "        self.bad_words = set()\n",
    "        with open('bad-words.txt', encoding = 'utf-8') as iFile:\n",
    "            for row in iFile:\n",
    "                self.bad_words.add(row.strip())\n",
    "\n",
    "    \n",
    "    def count_bad_words(self, sentence):\n",
    "       # Returns the number of bad words in string\n",
    "         \n",
    "        num_bad_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.bad_words:\n",
    "                num_bad_words += 1\n",
    "        return num_bad_words\n",
    "    \n",
    "    def bad_words_present (self, sentence):\n",
    "        #  Returns 1 if bad word in string, 0 if not\n",
    "           \n",
    "        bad_word_present = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.bad_words:\n",
    "                bad_word_present = 1\n",
    "        return bad_word_present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8f5e4-d6c7-4312-b949-e830f6ef6b19",
   "metadata": {},
   "source": [
    "#### Training data\n",
    "\n",
    "Instantiate the OC classifier, loop over X_txt_train, append to new list and cast to array to create a new feature: X_train_off_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47917600-65c0-49a1-9940-71b173ed6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "myOC = OffensiveClassifier()\n",
    "\n",
    "X_train_off_count = [] \n",
    "\n",
    "for item in X_txt_train:\n",
    "    bad_count = myOC.count_bad_words(item)\n",
    "    X_train_off_count.append([bad_count])\n",
    "\n",
    "X_train_off_count = np.array(X_train_off_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff8856-71f7-4935-b6a0-279e707d5291",
   "metadata": {},
   "source": [
    "#### For the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eebfe8c-49d2-4d4d-a2a3-f81c6319f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "myOC = OffensiveClassifier()\n",
    "\n",
    "X_test_off_count = [] \n",
    "\n",
    "for item in X_txt_test:\n",
    "    bad_count = myOC.count_bad_words(item)\n",
    "    X_test_off_count.append([bad_count])\n",
    "\n",
    "X_test_off_count = np.array(X_test_off_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831914d-98e1-4d8e-b04f-44ec4cbded2f",
   "metadata": {},
   "source": [
    "### Step 7: CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efcacde-64b9-4e67-86dd-0893d66d65f1",
   "metadata": {},
   "source": [
    "#### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baaf5c29-cb7e-455b-8ee5-eb4883f3e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10592, 97807)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "X_train_sparse = vec.fit_transform(X_txt_train)\n",
    "\n",
    "print(X_train_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0ab4f-8d09-40ea-aa65-72e8ee63a52c",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60e81a0c-a3ff-49ab-8f99-eb6c35e50947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2648, 97807)\n"
     ]
    }
   ],
   "source": [
    "X_test_sparse = vec.transform(X_txt_test)\n",
    "print(X_test_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8661a540-f104-474c-888a-2f7bd5258d2e",
   "metadata": {},
   "source": [
    "### Step 8: Train the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e60c150-4a6e-4fae-9946-632b43f4d52e",
   "metadata": {},
   "source": [
    "Only do this step for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dec77be-1123-4ddc-b78d-3444a5251b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "# if we use .toarray() we will get a dense matrix instead of the sparse matrix given. \n",
    "# The sparse matrix does not include all the zero values a dense matrix would\n",
    "X_train_total = hstack([X_train_sparse, X_train_off_count, X_train_all_targets, X_train_pos_neg])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_total, y_txt_train, test_size=.2) # 80/20 percent split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c39c3796-ade5-4356-90c9-fcdf755e1999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 macro: 0.5062340278713133\n",
      "f1 micro: 0.7277\n",
      "accuracy: 0.7277017461066541\n",
      "Precision: 0.5975\n",
      "Recall: 0.4894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, recall_score, accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore') #turning off convergence warnings because they are annoying!\n",
    "\n",
    "# all target words, offensive count, and pos/neg lexicon\n",
    "\n",
    "svc = LinearSVC() \n",
    "\n",
    "parameters = {'C':[0.01, 0.1, 1., 10.]}\n",
    "\n",
    "clf = GridSearchCV(svc, parameters, cv=5, scoring = \"f1_macro\")\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "macrof1 = f1_score(y_test, preds,average = 'macro')\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds, average = 'macro') \n",
    "recall = recall_score(y_test, preds, average = 'macro') \n",
    "microf1 = f1_score(y_test, preds, average = 'micro')\n",
    "print('f1 macro:', macrof1)\n",
    "print(\"f1 micro: {:.4f}\".format(microf1))\n",
    "print(\"accuracy: {}\".format(accuracy))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aaccf0f-c0dc-4be9-9455-e5143b7a4856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data: 0.9964593414375074\n"
     ]
    }
   ],
   "source": [
    "# We can see our model is ~99% accurate on the training dataset\n",
    "preds_train = clf.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, preds_train)\n",
    "print(\"accuracy on training data: {}\".format(accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13413d53-423c-4da6-915b-429bc103039e",
   "metadata": {},
   "source": [
    "### Error Analysis on Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6eda220-dea3-4077-8097-21d255a94dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tweets: 2119\n",
      "False Positive: 160\n",
      "False Negative: 363\n"
     ]
    }
   ],
   "source": [
    "num_tweets = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "for pred, y, txt in zip(preds, y_test, X_txt_train):\n",
    "    if pred == \"TIN\" and y == \"NOT\":\n",
    "        false_pos += 1\n",
    "    if pred == \"UNT\" and y == \"NOT\":\n",
    "        false_pos += 1\n",
    "    if pred == \"NOT\" and y == \"UNT\":\n",
    "        false_neg += 1\n",
    "    if pred == \"NOT\" and y == \"TIN\":\n",
    "        false_neg += 1\n",
    "     \n",
    "    num_tweets += 1\n",
    "    #if num_tweets == 1000:\n",
    "        #break\n",
    "print(\"Total Tweets: {}\".format(num_tweets))\n",
    "print(\"False Positive: {}\".format(false_pos))\n",
    "print(\"False Negative: {}\".format(false_neg)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e68afe24-13e9-4951-836d-9ad82ecb6625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: @USER She should ask a few native Americans what their take on this is.\n",
      "Ground-Truth Class: NOT\n",
      "Prediction: NOT\n",
      "\n",
      "Tweet: @USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL\n",
      "Ground-Truth Class: NOT\n",
      "Prediction: NOT\n",
      "\n",
      "Tweet: Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
      "Ground-Truth Class: NOT\n",
      "Prediction: NOT\n",
      "\n",
      "Tweet: @USER Someone should'veTaken\" this piece of shit to a volcano. 😂\"\n",
      "Ground-Truth Class: TIN\n",
      "Prediction: NOT\n",
      "\n",
      "Tweet: @USER @USER Obama wanted liberals &amp; illegals to move into red states\n",
      "Ground-Truth Class: NOT\n",
      "Prediction: NOT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_tweets = 0\n",
    "for pred, y, txt in zip(preds, y_test, X_txt_train):\n",
    "    print(\"Tweet: {}\".format(txt))\n",
    "    print(\"Ground-Truth Class: {}\".format(y))\n",
    "    print(\"Prediction: {}\".format(pred))\n",
    "    print()\n",
    "  \n",
    "    num_tweets += 1\n",
    "    if num_tweets == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c89573e-7974-4262-8e31-e01959892454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: @USER Been a Willie fan since before most of you were born....LOVE that he is holding a rally with Beto.... Exactly WHICH fans are furious?  Could you give some specifics? URL\n",
      "Ground-Truth Class: UNT\n",
      "Prediction: NOT\n",
      "\n",
      "Tweet: @USER @USER No conflict here—don’t look at this.  #Soros involved in violent left agenda of Antifa also.\n",
      "Ground-Truth Class: UNT\n",
      "Prediction: TIN\n",
      "\n",
      "Tweet: @USER Holder needs to be prosecuted\n",
      "Ground-Truth Class: UNT\n",
      "Prediction: NOT\n",
      "\n",
      "Tweet: *babysitting 3 kids*  people:”how old do you think she is?” “she has three kids”  me:*dont get mad. don’t get mad. they don’t know. they don’t know*\n",
      "Ground-Truth Class: UNT\n",
      "Prediction: NOT\n",
      "\n",
      "Tweet: @USER @USER Try looking for plain old democrats.  The liberals are the ones which you can’t have a conversation with.\n",
      "Ground-Truth Class: UNT\n",
      "Prediction: UNT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can check the performance on any particular class to see if there are clues when it isn't predicting properly\n",
    "num_tweets = 0\n",
    "for pred, y, txt in zip(preds, y_test, X_txt_train):\n",
    "    if y == \"UNT\":\n",
    "        print(\"Tweet: {}\".format(txt))\n",
    "        print(\"Ground-Truth Class: {}\".format(y))\n",
    "        print(\"Prediction: {}\".format(pred))\n",
    "        print()\n",
    "  \n",
    "        num_tweets += 1\n",
    "        if num_tweets == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2fd0a-cfd4-4a55-867a-f97ed57fe232",
   "metadata": {},
   "source": [
    "### Step 9: Input the Test data into the model and save the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82687436-a0ee-4c44-9362-72e9eb7266b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_total = hstack([X_test_sparse, X_test_off_count, X_test_all_targets, X_test_pos_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e1923c0-7f70-4725-b3af-d265f1316a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = clf.predict(X_test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e7e4658-73db-416c-b8e4-bfc4edc7000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = np.dstack((ID_txt_test, X_txt_test, test_preds))\n",
    "\n",
    "test_out = test_output.reshape(len(X_txt_test),3)\n",
    "\n",
    "np.savetxt('output.tsv', test_out,delimiter=\"\\t\",fmt='%s',encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9dd181-d206-449a-89c3-aed523646bfd",
   "metadata": {},
   "source": [
    "### Step 10: Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0624a99e-ac2e-461e-a3fb-6087b7372b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: @USER Nancy Lee Grahn You Are Awesome! I have been a fan since Santa Barbara!! Alex Davis also Rocks!!!!! Thank you !!!\n",
      "Prediction: NOT\n",
      "\n",
      "Tweet: @USER She is a Skrull. Enemy of The Kree. The Kree are who gave Carol her powers and whose uniform she is wearing in the first few moments of the trailer.\n",
      "Prediction: TIN\n",
      "\n",
      "Tweet: @USER @USER @USER @USER @USER @USER @USER Except you kind of are when it comes to gun control\n",
      "Prediction: NOT\n",
      "\n",
      "Tweet: @USER @USER @USER You are so beautiful♡\n",
      "Prediction: NOT\n",
      "\n",
      "Tweet: @USER This is what happens when liberals get in control\n",
      "Prediction: NOT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_tweets = 0\n",
    "for pred, txt in zip(test_preds, X_txt_test):\n",
    "    print(\"Tweet: {}\".format(txt))\n",
    "    print(\"Prediction: {}\".format(pred))\n",
    "    print()\n",
    "  \n",
    "    num_tweets += 1\n",
    "    if num_tweets == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f845c1e-fee0-4d90-8bee-718c51df6a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: @USER I see boobs lol 😂😜😘😇\n",
      "Prediction: UNT\n",
      "\n",
      "Tweet: @USER I never said that. I merely refuted the statement that they don’t have a tight end. Virgil Green is a solid tight end when he is surrounded by the talent that the chargers have\n",
      "Prediction: UNT\n",
      "\n",
      "Tweet: @USER Fuck the NFL\n",
      "Prediction: UNT\n",
      "\n",
      "Tweet: @USER You’re welcome! Yo! @USER and I were holding up a casual tournament watching you. Good shit!\n",
      "Prediction: UNT\n",
      "\n",
      "Tweet: @USER what the fuck...\n",
      "Prediction: UNT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the performance on any particular class to see if there are clues when it isn't predicting properly\n",
    "num_tweets = 0\n",
    "for pred, txt in zip(test_preds, X_txt_test):\n",
    "    if pred == \"UNT\":\n",
    "        print(\"Tweet: {}\".format(txt))\n",
    "        print(\"Prediction: {}\".format(pred))\n",
    "        print()\n",
    "  \n",
    "        num_tweets += 1\n",
    "        if num_tweets == 5:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
